{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this file I will build the Neural Network and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Lambda\n",
    "from keras.layers import Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "num_classes = 12\n",
    "epochs = 50\n",
    "l = 10\n",
    "num_filter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "class_name = np.load(\"class_name.npy\")\n",
    "x_list = []\n",
    "\n",
    "file_list = os.listdir(\".\")\n",
    "\n",
    "for file in file_list:\n",
    "    if file.startswith(\"x_train\") and file.endswith(\".npy\"):\n",
    "        x_list.append(file)\n",
    "\n",
    "x_train = np.load(x_list[0])\n",
    "# print(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_2d(inputs, rotation=0, horizontal_flip=False, vertical_flip=False):\n",
    "    \"\"\"Apply additive augmentation on 2D data.\n",
    "    # Arguments\n",
    "      rotation: A float, the degree range for rotation (0 <= rotation < 180),\n",
    "          e.g. 3 for random image rotation between (-3.0, 3.0).\n",
    "      horizontal_flip: A boolean, whether to allow random horizontal flip,\n",
    "          e.g. true for 50% possibility to flip image horizontally.\n",
    "      vertical_flip: A boolean, whether to allow random vertical flip,\n",
    "          e.g. true for 50% possibility to flip image vertically.\n",
    "    # Returns\n",
    "      input data after augmentation, whose shape is the same as its original.\n",
    "    \"\"\"\n",
    "    if inputs.dtype != tf.float32:\n",
    "        inputs = tf.image.convert_image_dtype(inputs, dtype=tf.float32)\n",
    "\n",
    "    with tf.name_scope('augmentation'):\n",
    "        shp = tf.shape(inputs)\n",
    "        batch_size, height, width = shp[0], shp[1], shp[2]\n",
    "        width = tf.cast(width, tf.float32)\n",
    "        height = tf.cast(height, tf.float32)\n",
    "\n",
    "        transforms = []\n",
    "        identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n",
    "\n",
    "        if rotation > 0:\n",
    "            angle_rad = rotation * 3.141592653589793 / 180.0\n",
    "            angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n",
    "            f = tf.contrib.image.angles_to_projective_transforms(angles,\n",
    "                                                                 height, width)\n",
    "            transforms.append(f)\n",
    "\n",
    "        if horizontal_flip:\n",
    "            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
    "            shape = [-1., 0., width, 0., 1., 0., 0., 0.]\n",
    "            flip_transform = tf.convert_to_tensor(shape, dtype=tf.float32)\n",
    "            flip = tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1])\n",
    "            noflip = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\n",
    "            transforms.append(tf.where(coin, flip, noflip))\n",
    "\n",
    "        if vertical_flip:\n",
    "            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
    "            shape = [1., 0., 0., 0., -1., height, 0., 0.]\n",
    "            flip_transform = tf.convert_to_tensor(shape, dtype=tf.float32)\n",
    "            flip = tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1])\n",
    "            noflip = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\n",
    "            transforms.append(tf.where(coin, flip, noflip))\n",
    "\n",
    "    if transforms:\n",
    "        f = tf.contrib.image.compose_transforms(*transforms)\n",
    "        inputs = tf.contrib.image.transform(inputs, f, interpolation='BILINEAR')\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input):\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(relu)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition(input):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(num_filter, (1,1), use_bias=False ,padding='same')(relu)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(300, 300, 3,))\n",
    "augment = Lambda(augment_2d,\n",
    "                 input_shape=x_train.shape[1:],\n",
    "                 arguments={'rotation': 8.0, 'horizontal_flip': True, 'vertical_flip':True})(input)\n",
    "\n",
    "First_Conv2D = Conv2D(num_filter, (7,7), use_bias=False ,padding='same')(augment)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D)\n",
    "First_Transition = add_transition(First_Block)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition)\n",
    "Second_Transition = add_transition(Second_Block)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition)\n",
    "Third_Transition = add_transition(Third_Block)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert model into JSON Format\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in x_list:\n",
    "    x_train = np.load(file)\n",
    "    y_name = \"y\" + file[1:]\n",
    "#     print(y_name)\n",
    "    y_train = np.load(y_name)\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                     validation_split=0.1,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"finished.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
